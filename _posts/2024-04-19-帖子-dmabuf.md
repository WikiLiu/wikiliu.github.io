---
title: "Dma-buf"
date: 2024-05-07T15:47:30-04:00
classes: wide
categories:
  - 收藏
tags:
  - LINUX
---

![dma flow](/assets/images/dma.png)

## dma-buf
dma_buf_attach 计数器+1（callback attach()），指出importdevice
device指针可以指出device_dma_parameters，代表dma支持情况

dma_buf_map_attachment 做dma映射

## dma-fence
fence包括dmafence，就是softfence。还有hardware fence，这个fence和dmafence有对应关系。driver初始化阶段会在pcie地址空间分一段fencebuffer供GPU同步fence。driver下ringbuffer的时候，指定的dmafence关联的hardware fence就会插到ringbuffer的后面，当task完成后ringbuffer的fence就会flush到fencebuffer，此时driver就可以做fence signal和fence callback。


## drm_mm
在 Linux 的 Direct Rendering Manager (DRM) 子系统中，drm_mm 和 drm_mm_node 是内存管理相关的两个不同的结构，它们在显存管理中扮演不同的角色，但彼此之间有紧密的联系。

drm_mm:
drm_mm 是一个表示整个显存管理器的结构体。它代表整个可用于分配的显存范围，通常包括了一些用于内存分配算法的元数据。
它通常包含了一系列 drm_mm_node 结构体，这些结构体代表了已经分配的内存块或者空闲内存块。
drm_mm 结构体管理着显存的全局状态，提供了接口和算法来分配和释放内存块。
drm_mm_node:
drm_mm_node 是表示单个内存块的结构体。这些内存块可以是已经被分配或者是空闲的内存区域。
每个 drm_mm_node 实例都包含了关于这块内存的信息，如它的起始地址、大小、和任何对齐要求等。
drm_mm_node 结构体是 drm_mm 的子结构，用于管理显存中的具体内存块。
区别和联系:

区别: drm_mm 是内存管理器的结构，而 drm_mm_node 是表示单个内存块的结构。你可以将 drm_mm 理解为整个显存的库房管理员，而 drm_mm_node 就是库房里的一个个货架。
联系: drm_mm 通过内部的数据结构（如红黑树、链表等）维护和组织多个 drm_mm_node 实例。drm_mm_node 实例是 drm_mm 管理范畴内的，而且它们的创建、分配和释放都是通过 drm_mm 提供的函数来进行管理的。
在显存管理的过程中，drm_mm 提供了分配和释放内存的框架，而 drm_mm_node 提供了对具体内存块的描述。开发者通常会使用 drm_mm 提供的API来分配和管理显存，而 drm_mm_node 则是在这个过程中用来跟踪每一块分配出去的显存。
